# Assume this repo:
# is at ../cvelist
import pathlib
import os
import re
import orjson
import sys
import time
import threading
from pprint import pprint as pp
from contextlib import nullcontext as safe

cvelist = os.path.join(os.path.dirname(__file__), '../cves')
missing_repos = os.path.join(os.path.dirname(__file__), 'missing.txt')
output_file = os.path.join(os.path.dirname(__file__), 'output.csv')
missing_file = os.path.join(os.path.dirname(__file__), 'output-missing.txt')
fix_file = os.path.join(os.path.dirname(__file__), 'output-fix.txt')
id_to_name = os.path.join(os.path.dirname(__file__), 'cve-id-to-name.json')
URL_REGEX = re.compile(r"https?://(?:www\.)?[-a-zA-Z0-9@:%._+~#=]{1,256}\.[a-zA-Z0-9()]{1,6}\b(?:[-a-zA-Z0-9()@:%_+.~#?&/=]*)")

class Spinner:
    busy = False
    delay = 0.1

    @staticmethod
    def spinning_cursor():
        while 1:
            for cursor in '|/-\\': yield cursor

    def __init__(self, delay=None):
        self.spinner_generator = self.spinning_cursor()
        if delay and float(delay): self.delay = delay

    def spinner_task(self):
        while self.busy:
            sys.stdout.write(next(self.spinner_generator))
            sys.stdout.flush()
            time.sleep(self.delay)
            sys.stdout.write('\b')
            sys.stdout.flush()

    def __enter__(self):
        self.busy = True
        threading.Thread(target=self.spinner_task).start()

    def __exit__(self, exception, value, tb):
        self.busy = False
        time.sleep(self.delay)
        if exception is not None:
            return False

class Repo:
	ids: tuple
	def __init__(self, name=None, vendor=None, url=None):
		self.ids = (str(name).lower(), str(vendor).lower())
		self.url = url
		self.matches = list()
		self.cve_vendor = list()
		self.cve_product = list()

	def match_with(self, vendors, products, urls):
		for i in range(len(vendors)):
			v = str(vendors[i]).lower()
			p = str(products[i]).lower()
			if v in self.ids and p in self.ids:
				return self.add_match([v], [p], [])

		url_matches = []
		for url in urls:
			if f"https://github.com/{self.url}".lower() in url.lower():
				url_matches.append(url)


		if url_matches and len(url_matches) > 0:
			self.add_match(vendors, products, url_matches)

	def add_match(self, vendor, product, urls):
		for u in urls:
			self.matches.append(u)
		for p in product:
			self.cve_product.append(p)
		for v in vendor:
			self.cve_vendor.append(v)


	def resolve(self):
		for i in range(len(self.cve_vendor)):
			if i >= len(self.cve_vendor):
				break
			ven = self.cve_vendor[i]
			prod = self.cve_product[i]
			if ven == self.ids[1].lower() and prod == self.ids[0].lower():
				self.cve_vendor = [ven]
				self.cve_product = [prod]

		for i in range(len(self.cve_product)):
			if i >= len(self.cve_product):
				break
			prod = self.cve_product[i]
			ven = self.cve_vendor[i]
			if str(self.url).lower() == str(prod).lower():
				self.cve_vendor = [self.ids[1]]
				self.cve_product = [self.ids[0]]

	def __str__(self):
		out = f"[ {self.url} ]\n"
		out += f"Vendor: {set(self.cve_vendor)}\nProduct: {set(self.cve_product)}\n"
		return out + "-"*80


	def __repr__(self):
		return self.__str__()

def read_data():
	id_map = dict()
	repos: list[Repo] = list()
	with open(missing_repos, 'r') as f:
		for repo in f:
			repo = repo.strip()
			vendor, name = repo.strip().split('/')
			repos.append(Repo(name, vendor, repo))

	with open(id_to_name, 'r') as f:
		id_map = orjson.loads(f.read())

	return repos, id_map

def parse_jsons(repos):
	cvelist_path = pathlib.Path(cvelist)
	for p in cvelist_path.rglob("CVE*.json"):
		with open(p, 'r') as f:
			try:
				data_str = f.read()
				data = orjson.loads(data_str)

				affected = data.get("containers", {}).get("cna", {}).get("affected", [])
				products = list([
					a.get("product") for a in affected
				])
				vendors = list([
					a.get("vendor") for a in affected
				])
				urls = re.findall(URL_REGEX, data_str)

				for repo in repos:
					repo.match_with(vendors, products, urls)

			except UnicodeDecodeError as e:
				print(e.reason)
				print(f"ERROR loading {p}")

def generate_outputs(repos):
	output_missing = ""
	output_fix = ""
	output = ""

	for repo in repos:
		repo.resolve()
		if len(repo.cve_vendor) + len(repo.cve_product) == 0:
			output_missing += f"{repo.url}\n"
		elif len(repo.cve_vendor) > 1 or len(repo.cve_product) > 1:
			output_fix += f"{repo}\n"
		elif len(repo.cve_vendor) + len(repo.cve_product) == 1:
			output_fix += f"{repo}\n"
		else:
			ven = repo.cve_vendor.pop() if len(repo.cve_vendor) > 0 else None
			prod = repo.cve_product.pop() if len(repo.cve_product) > 0 else None
			if ven == prod and ven == "n/a":
				output_fix += f"{repo}\n"
			elif ven and prod:
				output += f"{repo.url},{ven},{prod}\n"
			elif not ven and not prod:
				output_fix += f"{repo}\n"
			else:
				output_fix += f"{repo}\n"

	return output, output_missing, output_fix

def write_output(output, output_missing, output_fix):
	with open(output_file, 'w') as f:
		f.write(output)

	print("\bWriting Missing Output")
	with open(missing_file, 'w') as f:
		f.write(output_missing)

	print("\bWriting Fix Output")
	with open(fix_file, 'w') as f:
		f.write(output_fix)

def main():
	with Spinner():
		print("\bReading Data...")
		repos, id_map = read_data()

		print("\bParsing Jsons...")
		parse_jsons(repos)

		print("\bCreating Outputs")

		output, output_missing, output_fix = generate_outputs(repos)

		print("\bWriting Output")
		write_output(output, output_missing, output_fix)

if __name__ == "__main__":
	main()
